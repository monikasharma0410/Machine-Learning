
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error

data = fetch_california_housing()
X, y = data.data, data.target

scaler = StandardScaler()
X = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

class LinearRegressionGD:
# --- Part (a): Implementation of the Linear Regression Model ---
    def __init__(self, learning_rate=0.01, n_iterations=1000):
        self.learning_rate = learning_rate
        self.n_iterations = n_iterations
        self.mse_history=[]

    def fit(self, X, y):
        n_samples, n_features = X.shape
        self.weights = np.zeros(n_features)
        self.bias = 0

        #Gradient descent loop
        for _ in range(self.n_iterations):
            y_predicted = np.dot(X, self.weights) + self.bias
            error = y_predicted - y

            # Compute gradients
            dw = (1/n_samples) * np.dot(X.T, error)
            db = (1/n_samples) * np.sum(error)

            # Update parameters
            self.weights -= self.learning_rate * dw
            self.bias -= self.learning_rate * db

            #compute and store MSE at each step
            mse=(1/n_samples)*np.sum(error**2)
            self.mse_history.append(mse)

            # Safety check: break if weights explode
            if np.any(np.isnan(self.weights)) or np.any(np.isinf(self.weights)):
                print("Divergence detected! Try reducing learning rate.")
                break

    def predict(self, X):
        return np.dot(X, self.weights) + self.bias

# Step 5: Train model
model = LinearRegressionGD(learning_rate=0.01, n_iterations=1000)
model.fit(X_train, y_train)

# Step 6: Predictions & Evaluation
y_pred = model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
mae= mean_absolute_error(y_test,y_pred)

print("Mean Squared Error (MSE):", mse)
print("Mean Absolute Error(MAE):", mae)

# Visualization: Plot MSE over iterations
plt.plot(model.mse_history, label="Training MSE")
plt.xlabel("Iterations")
plt.ylabel("Mean Squared Error")
plt.title("Convergence of Gradient Descent")
plt.legend()
plt.show()

r2=r2_score(y_test,y_pred)
print("R-squared(R2):", r2)

# ---- 2(a). Visualization: Learning Curve ----
plt.plot(range(len(model.mse_history)), model.mse_history, marker='o')
plt.xlabel("Iterations")
plt.ylabel("Mean Squared Error (MSE)")
plt.title("Learning Curve (MSE over Iterations)")
plt.grid(True)
plt.show()

# ---- 2(b). Visualization: Actual vs Predicted ----
plt.scatter(y_test, y_pred, color="blue", alpha=0.6, edgecolor="k")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # 45Â° reference line
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Actual vs Predicted Values")
plt.grid(True)
plt.show()


